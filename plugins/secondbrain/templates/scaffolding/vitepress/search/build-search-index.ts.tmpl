/**
 * Build Search Index Script
 *
 * Generates an Orama-compatible search index from markdown documents.
 * Run during build: npm run docs:build
 *
 * Usage:
 *   npx tsx docs/.vitepress/search/build-search-index.ts
 */

import * as fs from 'fs'
import * as path from 'path'
import matter from 'gray-matter'

interface SearchDocument {
  id: string
  entity: string
  title: string
  content: string
  path: string
  metadata: Record<string, any>
}

interface SearchIndex {
  version: string
  generated: string
  documents: SearchDocument[]
}

// Configuration
const DOCS_DIR = path.resolve(__dirname, '../../')
const OUTPUT_FILE = path.resolve(DOCS_DIR, '.vitepress/dist/search-index.json')
const ENTITY_DIRS = ['adrs', 'notes', 'tasks', 'discussions']

// Skip patterns
const SKIP_PATTERNS = [
  /TEMPLATE\.md$/,
  /index\.md$/,
  /\.vitepress/,
]

function shouldSkip(filePath: string): boolean {
  return SKIP_PATTERNS.some(pattern => pattern.test(filePath))
}

function extractEntity(filePath: string): string {
  for (const entity of ENTITY_DIRS) {
    if (filePath.includes(`/${entity}/`) || filePath.includes(`\\${entity}\\`)) {
      return entity
    }
  }
  return 'docs'
}

function getDocPath(filePath: string, docsDir: string): string {
  const relativePath = path.relative(docsDir, filePath)
  // Convert to URL path (remove .md extension)
  return '/' + relativePath.replace(/\.md$/, '').replace(/\\/g, '/')
}

function truncateContent(content: string, maxLength: number = 2000): string {
  // Remove markdown syntax for cleaner content
  const cleaned = content
    .replace(/^#+\s+.*/gm, '') // Remove headers
    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // Replace links with text
    .replace(/`{1,3}[^`]*`{1,3}/g, '') // Remove code blocks
    .replace(/[*_~]+/g, '') // Remove formatting
    .replace(/\n{2,}/g, '\n') // Collapse multiple newlines
    .trim()

  if (cleaned.length <= maxLength) return cleaned
  return cleaned.slice(0, maxLength) + '...'
}

function processMarkdownFile(filePath: string, docsDir: string): SearchDocument | null {
  try {
    const fileContent = fs.readFileSync(filePath, 'utf-8')
    const { data: frontmatter, content } = matter(fileContent)

    // Skip files without proper content
    if (!content.trim()) return null

    const entity = extractEntity(filePath)
    const docPath = getDocPath(filePath, docsDir)

    // Extract title from frontmatter or first heading
    let title = frontmatter.title
    if (!title) {
      const headingMatch = content.match(/^#\s+(.+)$/m)
      title = headingMatch ? headingMatch[1] : path.basename(filePath, '.md')
    }

    // Generate unique ID
    const id = docPath.replace(/\//g, '-').replace(/^-/, '')

    return {
      id,
      entity,
      title,
      content: truncateContent(content),
      path: docPath,
      metadata: {
        ...frontmatter,
        filePath: path.relative(docsDir, filePath)
      }
    }
  } catch (error) {
    console.error(`Error processing ${filePath}:`, error)
    return null
  }
}

function findMarkdownFiles(dir: string, files: string[] = []): string[] {
  const entries = fs.readdirSync(dir, { withFileTypes: true })

  for (const entry of entries) {
    const fullPath = path.join(dir, entry.name)

    if (entry.isDirectory()) {
      // Skip hidden directories and node_modules
      if (!entry.name.startsWith('.') && entry.name !== 'node_modules') {
        findMarkdownFiles(fullPath, files)
      }
    } else if (entry.isFile() && entry.name.endsWith('.md')) {
      if (!shouldSkip(fullPath)) {
        files.push(fullPath)
      }
    }
  }

  return files
}

async function buildIndex(): Promise<void> {
  console.log('Building search index...')
  console.log(`Docs directory: ${DOCS_DIR}`)

  // Find all markdown files
  const markdownFiles = findMarkdownFiles(DOCS_DIR)
  console.log(`Found ${markdownFiles.length} markdown files`)

  // Process each file
  const documents: SearchDocument[] = []

  for (const filePath of markdownFiles) {
    const doc = processMarkdownFile(filePath, DOCS_DIR)
    if (doc) {
      documents.push(doc)
    }
  }

  console.log(`Processed ${documents.length} documents`)

  // Create index
  const index: SearchIndex = {
    version: '1.0',
    generated: new Date().toISOString(),
    documents
  }

  // Ensure output directory exists
  const outputDir = path.dirname(OUTPUT_FILE)
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true })
  }

  // Write index
  fs.writeFileSync(OUTPUT_FILE, JSON.stringify(index, null, 2))
  console.log(`Search index written to: ${OUTPUT_FILE}`)

  // Stats
  const stats = documents.reduce((acc, doc) => {
    acc[doc.entity] = (acc[doc.entity] || 0) + 1
    return acc
  }, {} as Record<string, number>)

  console.log('\nIndex statistics:')
  for (const [entity, count] of Object.entries(stats)) {
    console.log(`  ${entity}: ${count}`)
  }
}

// Run build
buildIndex().catch(console.error)
